---
title: Understanding the Process of Reading
author: Benjamin T. Carter
date: 2019-10-24
output: word_document
---

### Environment

```{r message = FALSE}
library(dplyr)
library(readxl)
library(tidyr)
library(lme4)
library(lmerTest)
library(sjPlot)
library(ggplot2)
```

## Data Viewer cleaning

These are some shortcuts that can be used to view the cleaning stats via command line.

```{bash}
# DIRECT=~/Box/LukeLab/UnderstandingTheProcessOfReading/data
# DATA=${DIRECT}/cleaning\ -\ UPoR1.txt # file with cleaning stats

# mv $DATA ${DIRECT}/cleaning-UPoR1.txt
# DATA=${DIRECT}/cleaning-UPoR1.txt

# tail -2 ${DATA}/cleaning-UPoR1.txt # read in last two lines
```

```{r echo=FALSE, error=FALSE, message=FALSE}
MERGED <- 738
DELETED <- 9985
DIR <- file.path("~","Box","LukeLab","UnderstandingTheProcessOfReading","data") # study directory
FIXS <- read.table(file.path(DIR,"FixList.xls"), header = TRUE, sep = "\t") # list of fixations
TOTAL <- as.numeric(count(FIXS)) # count total number of fixation events
REMAIN <- (MERGED + DELETED) / TOTAL
PER <- REMAIN*100 # percent of fixations that were excluded or merged.
```

`r PER`% of the fixations were excluded or merged by Data Viewer.

## Behavior

### Data Cleaning and Aggregation

The following steps were taken during preprocessing and cleaning of the data:

1. 9 total participants were excluded from the study due to poor eye tracking.
2. Lexical predictability values were then referenced from the Provo Corpus and inserted as a variable.
3. The variable `windowcondition` was changed from a numeric to a factor.
4. `Text_ID` was changed from a string to a factor.
5. `IA_ID` was changed from a numeric to a factor.
6. The names of the levels for `windowcondition` were changed such that 0 became "No Preview" and 1 became "Preview" for ease of comparison and graphing later.
1. A variable for the location of the first fixation was created (`FIRST_LANDING`).

```{r error=FALSE, message=FALSE, echo=FALSE}
# read in the data
DIR <- file.path("~","Box","LukeLab","UnderstandingTheProcessOfReading","data") # study directory
REPORT <- read.delim(file.path(DIR,"IA_report_UPoR1.txt"), header = TRUE, sep = "\t", fill = TRUE, na.strings = ".") # interest areas report
ORTHOS <- read.csv(file.path(DIR,"Provo_Corpus-Eyetracking_Data.csv"), header = TRUE, sep = ",", fill = TRUE) # ortho probabilities

# clean the interest areas report
REPORT$RECORDING_SESSION_LABEL <- tolower(REPORT$RECORDING_SESSION_LABEL) # make label case consistent

exclude <- c("s32", "s46", "s53", "s54", "s56", "s57", "s59", "s60", "s63") # exclude bad data
REPORT <- REPORT %>% subset(!(RECORDING_SESSION_LABEL %in% exclude))


# aggregate the Provo Corpus and join to the interest areas report
COMBINED <- ORTHOS[c("Text_ID","IA_ID","OrthoMatchModel")] %>% 
  group_by(Text_ID, IA_ID) %>%
  summarize(mean_OrthoMatchModel = mean(OrthoMatchModel)) %>%
  ungroup() %>%
  right_join(REPORT,
             by = c("Text_ID" = "textnumber", "IA_ID" = "IA_ID")
             )

COMBINED <- COMBINED[!is.na(COMBINED$mean_OrthoMatchModel),] # remove na values
rm(ORTHOS, REPORT) # unload unneeded data

# need to add demographic data to this too!

# change classes
COMBINED$windowcondition <- as.factor(COMBINED$windowcondition)
COMBINED$Text_ID <- as.factor(COMBINED$Text_ID)
COMBINED$IA_ID <- as.factor(COMBINED$IA_ID)
levels(COMBINED$windowcondition) <- list("No Preview"="0", "Preview" = "1")

# add variable for how far into a word someone fixated
COMBINED <- COMBINED %>%
  mutate(
    FIRST_LANDING = (IA_FIRST_FIXATION_X - IA_LEFT) / (IA_RIGHT - IA_LEFT)
  )

COMBINED$WORD_ID <- interaction(COMBINED$Text_ID, COMBINED$IA_ID, sep = ".") # create interaction variable

# check out https://link.springer.com/article/10.3758/s13414-018-1581-0
# log transform dependent variables, add additional variables from ^paper^
```

### Summary Statistics by Window Condition

```{r error=FALSE, message=FALSE, echo=FALSE}
# Skipping, refixation and regression probability
mean_sd <- function(a) {
  b <- round(mean(a, na.rm = TRUE), digits = 2)
  c <- round(sd(a, na.rm = TRUE), digits = 2)
  return(paste(b," (",c,")",sep=""))
}

sumStats1 <- COMBINED %>%
  group_by(windowcondition, WORD_ID) %>%
  summarise(
    skipping_prob = sum(IA_SKIP)/n(),
    refixation_prob = sum(IA_FIXATION_COUNT >= 2)/n(),
    regression_prob = sum(IA_REGRESSION_IN, na.rm = TRUE)/n()
  ) %>%
  ungroup() %>%
  group_by(windowcondition) %>%
  summarise(
    "Skipping probability" = mean_sd(skipping_prob),
    "Refixation probability" = mean_sd(refixation_prob),
    "Regression probability" = mean_sd(regression_prob)
  ) %>%
  gather(Statistic, Value, "Skipping probability":"Regression probability") %>%
  spread(windowcondition, Value)

# first fixation duration, location and dwell time
sumStats2 <- COMBINED %>%
  group_by(windowcondition) %>%
  summarize(
    "First Fixation Duration" = mean_sd(IA_FIRST_FIXATION_DURATION),
    "First Fixation Location" = mean_sd(FIRST_LANDING),
    "Dwell Time" = mean_sd(IA_DWELL_TIME),
    "Gaze Duration" = mean_sd(IA_FIRST_RUN_DWELL_TIME)
    ) %>%
  gather(Statistic, Value, "First Fixation Duration":"Gaze Duration") %>%
  spread(windowcondition, Value)

# combine into single table
sumStats <- rbind(sumStats2,sumStats1)
knitr::kable(sumStats)
```

### Visualizing trends

I constructed some visualizations of the effect of window condition and text predictability on first fixation duration, gaze duration, and total dwell time. The most pronounced effects are for the first fixation.

```{r error=FALSE, message=FALSE, echo=FALSE}
ggplot(COMBINED %>% filter(IA_DWELL_TIME > 0), 
       aes(x = log(mean_OrthoMatchModel), y = IA_FIRST_FIXATION_DURATION, fill = windowcondition)) +
  geom_smooth(method = "lm") +
  labs(
    title = "The Effect of Preview and Frequency on First Fixation Duration ",
    x = "log Predictability",
    y = "First Fixation Duration (ms)",
    fill = "Window Condition"
  )

ggplot(COMBINED %>% filter(IA_DWELL_TIME > 0), 
       aes(x = log(mean_OrthoMatchModel), y = IA_FIRST_RUN_DWELL_TIME, fill = windowcondition)) +
  geom_smooth(method = "lm") +
  labs(
    title = "The Effect of Preview and Frequency on Gaze Duration",
    x = "log Predictability",
    y = "Gaze Duration (ms)",
    fill = "Window Condition"
  )

ggplot(COMBINED %>% filter(IA_DWELL_TIME > 0), 
       aes(x = log(mean_OrthoMatchModel), y = IA_DWELL_TIME, fill = windowcondition)) +
  geom_smooth(method = "lm") +
  labs(
    title = "The Effect of Preview and Frequency on Dwell Time",
    x = "log Predictability",
    y = "Total Dwell Time (ms)",
    fill = "Window Condition"
  )

```

## Models

For the models below I excluded all interest areas that did not have a fixation.

### Model for First Fixation Duration

I constructed two models for Fixation Duration. The first incorporated random slopes by window condition for each participant. The second did not.

#### Model 1:

`log(IA_FIRST_FIXATION_DURATION) ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) + (1 + windowcondition|RECORDING_SESSION_LABEL) + (1|WORD_ID)`

```{r error=FALSE, message=FALSE, echo=FALSE}
# first fixation duration - failed to converge
# mod <- lmer(
#   log(IA_FIRST_FIXATION_DURATION) ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) +
#     (1 + windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE)|RECORDING_SESSION_LABEL) +
#     (1|WORD_ID),
#   data = COMBINED %>% filter(IA_DWELL_TIME > 0)
# )

  # second attempt - also failed to converge
# mod <- lmer(
#   log(IA_FIRST_FIXATION_DURATION) ~ windowcondition + scale(log(mean_OrthoMatchModel), scale = FALSE) +
#     (1 + windowcondition + scale(log(mean_OrthoMatchModel), scale = FALSE)|RECORDING_SESSION_LABEL) +
#     (1|WORD_ID),
#   data = COMBINED %>% filter(IA_DWELL_TIME > 0)
# )

  # third attempt - successful
mod1 <- lmer(
  log(IA_FIRST_FIXATION_DURATION) ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) +
    (1 + windowcondition|RECORDING_SESSION_LABEL) +
    (1|WORD_ID),
  data = COMBINED %>% filter(IA_DWELL_TIME > 0)
)
tab1 <- summary(mod1)
knitr::kable(tab1$coefficients[,-3], digits = 3)
```

#### Model 2:

`IA_FIRST_FIXATION_DURATION) ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) + (1|RECORDING_SESSION_LABEL) + (1|WORD_ID)`

```{r error=FALSE, message=FALSE, echo=FALSE}
  # fourth model - failed to converge
# mod <- lmer(
#   log(IA_FIRST_FIXATION_DURATION) ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) +
#     (1 + scale(log(mean_OrthoMatchModel), scale = FALSE)|RECORDING_SESSION_LABEL) +
#     (1|WORD_ID),
#   data = COMBINED %>% filter(IA_DWELL_TIME > 0)
# )

  # fifth model - successful
mod2 <- lmer(
  log(IA_FIRST_FIXATION_DURATION) ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) +
    (1|RECORDING_SESSION_LABEL) +
    (1|WORD_ID),
  data = COMBINED %>% filter(IA_DWELL_TIME > 0)
)
tab2 <- summary(mod2)
knitr::kable(tab2$coefficients[,-3], digits = 3)
```


### Model for Gaze Duration

`IA_FIRST_RUN_DWELL_TIME ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) + (1 + windowcondition|RECORDING_SESSION_LABEL) + (1|WORD_ID)`

```{r error=FALSE, message=FALSE, echo=FALSE}
# gaze duration 1 - boundary (singular)
# mod <- lmer(
#    IA_FIRST_RUN_DWELL_TIME ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) +
#      (1 + windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE)|RECORDING_SESSION_LABEL) +
#      (1|WORD_ID),
#    data = COMBINED
#  )

# gaze duration 2 - failed to converge
# mod <- lmer(
#    IA_FIRST_RUN_DWELL_TIME ~ windowcondition + scale(log(mean_OrthoMatchModel), scale = FALSE) +
#      (1 + windowcondition + scale(log(mean_OrthoMatchModel), scale = FALSE)|RECORDING_SESSION_LABEL) +
#      (1|WORD_ID),
#    data = COMBINED
#  )

# gaze duration 3
mod5 <- lmer(
   IA_FIRST_RUN_DWELL_TIME ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) +
     (1 + windowcondition|RECORDING_SESSION_LABEL) +
     (1|WORD_ID),
   data = COMBINED
 )
tab5 <- summary(mod5)
knitr::kable(tab5$coefficients[,-3], digits = 3)
```


### Model for Total Dwell Time

`log(IA_DWELL_TIME) ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) + (1 + windowcondition|RECORDING_SESSION_LABEL) + (1|WORD_ID)`

```{r error=FALSE, message=FALSE, echo=FALSE}
 # first model - failed to converge
# mod <- lmer(
#   log(IA_DWELL_TIME) ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) +
#     (1 + windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE)|RECORDING_SESSION_LABEL) +
#     (1|WORD_ID),
#   data = COMBINED
# )

  # second model - failed
# mod <- lmer(
#   log(IA_DWELL_TIME) ~ windowcondition + scale(log(mean_OrthoMatchModel), scale = FALSE) +
#     (1 + windowcondition + scale(log(mean_OrthoMatchModel), scale = FALSE)|RECORDING_SESSION_LABEL) +
#     (1|WORD_ID),
#   data = COMBINED
# )

  # third model
mod3 <- lmer(
  log(IA_DWELL_TIME) ~ windowcondition * scale(log(mean_OrthoMatchModel), scale = FALSE) +
    (1 + windowcondition|RECORDING_SESSION_LABEL) +
    (1|WORD_ID),
  data = COMBINED %>% filter(IA_DWELL_TIME > 0)
)
tab3 <- summary(mod3)
knitr::kable(tab3$coefficients[,-3], digits = 3)
```



