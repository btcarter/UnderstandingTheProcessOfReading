---
title: Understanding the Process of Reading
author: Benjamin T. Carter
date: 2019-10-24
output: word_document
---

## Environment

```{r echo = FALSE, message = FALSE}
library(dplyr)
library(readxl)
library(tidyr)
```

## Cleaning statistics
```{bash}
DIRECT=~/Box/LukeLab/UnderstandingTheProcessOfReading/data
DATA=${DIRECT}/cleaning\ -\ UPoR1.txt # file with cleaning stats

mv $DATA ${DIRECT}/cleaning-UPoR1.txt
DATA=${DIRECT}/cleaning-UPoR1.txt

MERGED=${tail -2 cleaning-UPoR1.txt} # read in last two lines
```

```{r}
MERGED <- 738
DELETED <- 9985
DIR <- file.path("~","Box","LukeLab","UnderstandingTheProcessOfReading","data") # study directory
FIXS <- read.table(file.path(DIR,"FixList.xls"), header = TRUE, sep = "\t") # list of fixations
TOTAL <- as.numeric(count(FIXS)) # count total number of fixation events
REMAIN <- (MERGED + DELETED) / TOTAL
REMAIN*100 # percent of fixations that were excluded or merged.
```

## Behavior

### Data Cleaning and Aggregation

Here are the paths to the data. Let's bring them together along common variables.

```{r}
# read in the data
DIR <- file.path("~","Box","LukeLab","UnderstandingTheProcessOfReading","data") # study directory
REPORT <- read.delim(file.path(DIR,"IA_report_UPoR1.txt"), header = TRUE, sep = "\t", fill = TRUE, na.strings = ".") # interest areas report
ORTHOS <- read.csv(file.path(DIR,"Provo_Corpus-Eyetracking_Data.csv"), header = TRUE, sep = ",", fill = TRUE) # ortho probabilities

# clean the interest areas report
REPORT <- REPORT[REPORT$IA_DWELL_TIME > 0,] # remove interest areas without a fixation in them.

# aggregate the Provo Corpus and join to the interest areas report
COMBINED <- ORTHOS[c("Text_ID","IA_ID","OrthoMatchModel")] %>% 
  group_by(Text_ID, IA_ID) %>%
  summarize(mean_OrthoMatchModel = mean(OrthoMatchModel)) %>%
  right_join(REPORT,
             by = c("Text_ID" = "textnumber", "IA_ID" = "IA_ID")
             )

COMBINED <- COMBINED[!is.na(COMBINED$mean_OrthoMatchModel),] # remove na values
rm(ORTHOS, REPORT) # unload unneeded data

# change classes
COMBINED$windowcondition <- as.factor(COMBINED$windowcondition)
COMBINED$Text_ID <- as.factor(COMBINED$Text_ID)
COMBINED$IA_ID <- as.factor(COMBINED$IA_ID)


```

### Models

```{r}
# load libraries
library(lme4)
library(lmerTest)

# models to compute
firstFixation <- lmer(
  IA_FIRST_FIXATION_DURATION ~ windowcondition +
    (1 + windowcondition|RECORDING_SESSION_LABEL) +
    (1 + windowcondition|Text_ID),
  data = COMBINED
  )

firstFixation <- lmer(
  IA_FIRST_FIXATION_DURATION ~ windowcondition +
    (1|RECORDING_SESSION_LABEL) +
    (1|Text_ID),
  data = COMBINED
  )

nextSaccade <- lmer()
```

### Summary Statistics
```{r}
# add at some point
```
